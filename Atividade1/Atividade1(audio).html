<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Teste de AR com Video</title>
</head>

<body>
    <!-- import aframe and then ar.js with image tracking / location based features -->
    <script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>
    <script src="https://aframe.io/releases/0.8.0/aframe.min.js"></script>
    <script src="https://cdn.rawgit.com/jeromeetienne/AR.js/1.6.0/aframe/build/aframe-ar.js"></script>

    <!--- Faz o som rodar? -->
    <script>
        //To avoid playing from start if the marker flickers, not sure if needed, but it might be a failsafe when you have mutiple markers and want to make sure the first finishes before launching the second
        var playing = false;

        //HTML5 audio, will need user touch input to start on mobile
        var intro = new Audio("https://raw.githack.com/BiaDobbs/AR_Experience/master/TesteAudio.mp3");

        //Detect end of audio
        intro.addEventListener("ended", function() {
            intro.currentTime = 0;
            playing = false;
        });

        AFRAME.registerComponent('markerhandler', {
            init: function() {
                // Set up the tick throttling. Will check if marker is active every 500ms
                this.tick = AFRAME.utils.throttleTick(this.tick, 500, this);
            },
            tick: function(t, dt) {

                if (document.querySelector("#homem").object3D.visible == true && playing == false) {
                    // MARKER IS PRESENT
                    intro.play();
                    playing = true;
                    print(vivo);
                } else {
                    // MARKER IS HIDDEN, do nothing (up to you)
                    print(morto);
                }

            }
        });

    </script>
    <!-- style for the loader -->
    <style>
        .arjs-loader {
            height: 100%;
            width: 100%;
            position: absolute;
            top: 0;
            left: 0;
            background-color: rgba(0, 0, 0, 0.8);
            z-index: 9999;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .arjs-loader div {
            text-align: center;
            font-size: 1.25em;
            color: white;
        }

    </style>

    <body style="margin : 0px; overflow: hidden;">
        <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
        <div class="arjs-loader">
            <div>Checando as histórias, por favor aguarde (e não esqueça de permitir a câmera!)</div>
        </div>

        <!-- a-frame scene -->
        <a-scene vr-mode-ui="enabled: false;" renderer="logarithmicDepthBuffer: true;" embedded arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;">
            <!-- a-nft is the anchor that defines an Image Tracking entity -->
            <!-- on 'url' use the path to the Image Descriptors created before. -->
            <!-- the path should end with the name without the extension e.g. if file is 'pinball.fset' the path should end with 'pinball' -->
            <a-assets>
                <audio id="invisiv" src="https://raw.githack.com/BiaDobbs/AR_Experience/master/TesteAudio.mp3"></audio>

            </a-assets>
            <a-nft videohandler type="nft" url='https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/BiaDobbs/AR_Experience/master/chaos' smooth="true" smoothCount="10" smoothTolerance=".01" smoothThreshold="5">

                <!-- as a child of the a-nft entity, you can define the content to show. -->
                <a-video src=#vid height='160' width='120'></a-video>

                <!-- /a-nft>

            <a-nft  type="nft" url='https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/BiaDobbs/AR_Experience/master/homem' smooth="true" smoothCount="10" smoothTolerance=".01" smoothThreshold="5" sound="src: #invisiv; volume:1">
                <a-box depth="200" height="200" width="200"></a-box>
            </a-nft-->
                <!-- static camera that moves according to the device movemenents -->
                <a-entity camera></a-entity>

                <a-marker-camera id="homem" preset='kanji'></a-marker-camera>
        </a-scene>
    </body>
</body>

</html>
